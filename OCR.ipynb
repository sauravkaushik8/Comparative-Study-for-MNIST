{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optical Character Recognition using Computer Vision\n",
    "\n",
    "##### Using MNIST DataSet of handwritten digits.\n",
    "\n",
    "#### By Saurav Kaushik & Manpreet Singh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### PROJECT NAME: Optical Character Recognition using Computer Vision\n",
    "\n",
    "### TECNOLOGY USED: Python, K-Nearest Neighbours, Support Vctor Machines, Decesion Trees, Extra Tree Regressor, Random Forest, Gradient Boosting Machines, Tensorflow, Keras.\n",
    "\n",
    "### MENTOR NAME: Mr. Vibhor.\n",
    "\n",
    "### Student NAMES: Saurav Kaushik and Manpreet Singh. \n",
    "\n",
    "### ROLL NUMBER: 00496403113 and 03396403113. \n",
    "\n",
    "### EMAIL ID: sauravkaushik8@gmail.com and manpreetsingh1795@gmail.com.\n",
    "\n",
    "### CONTACT MOBILE NUMBER: +91-9711710851 and +91-9716181884"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problem Statement:\n",
    "\n",
    "### Comparitive study of various Machine learning algorithms on basis of accuracies and training time for Optical character recognition using MNIST Dataet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two Types of Problems: \n",
    "\n",
    "# 1. Image Recognition (Not Well Defined) | Easy for Humans, Hard for Computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://lh5.ggpht.com/vuEsIAUPJGvdFiGrivXpbCLb-M9bxUTsGa0s5sbXNe-w_XPowdoa9OYC4xdxT30fwYY=h900\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://lh5.ggpht.com/vuEsIAUPJGvdFiGrivXpbCLb-M9bxUTsGa0s5sbXNe-w_XPowdoa9OYC4xdxT30fwYY=h900\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two Types of Problems: \n",
    "\n",
    "# 2. Solving equations (Well Defined) | Hard for Humans, Easy for Computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://blog.wolfram.com/data/uploads/2013/02/MakingCurves-Out39.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://blog.wolfram.com/data/uploads/2013/02/MakingCurves-Out39.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But with recent advancements in Machine Learning, computers are able to beat the benchmark of human image recognition\n",
    "\n",
    "## Let's check the comparitive performance of different algorithms for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vizualising the loaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEKCAYAAAAy4ujqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE9/hKCD+PwkK5g7COkEYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73951a20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Character no.\n",
    "i=10\n",
    "\n",
    "label = mnist.train.labels[i]\n",
    "\n",
    "pixels = mnist.train.images[i,:]\n",
    "\n",
    "pixels = np.array(pixels, dtype='float32')\n",
    "\n",
    "pixels = pixels.reshape(28, 28)\n",
    "\n",
    "plt.title('Label is {label}'.format(label=label))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Defining train and test Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Training image data\n",
    "train_images = mnist.train.images.reshape([55000, 784])\n",
    "\n",
    "#Training image labels\n",
    "train_target = mnist.train.labels\n",
    "\n",
    "#Testing image data\n",
    "test_images = mnist.test.images.reshape([10000, 784])\n",
    "\n",
    "#Testing image labels\n",
    "test_target = mnist.test.labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Using the KNN Classifier\n",
    "\n",
    "#Importing time library\n",
    "import time\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier() \n",
    "\n",
    "#Fit model with training data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "knn_time = time.clock() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96789999999999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057.117255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Using the SVM Classifier\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel = 'linear')\n",
    "\n",
    "#Fit model with sample data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "\n",
    "svm_time = time.clock() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93930000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662.775801"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using DT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Using the Decesion Tree Classifier\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "\n",
    "#Fit model with sample data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dt_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "dt_time = time.clock() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87229999999999996"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.97991899999988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using ET Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Using the Extra Tree Classifier\n",
    "start = time.clock()\n",
    "\n",
    "\n",
    "from sklearn import ensemble\n",
    "classifier = ensemble.ExtraTreesClassifier()\n",
    "\n",
    "#Fit model with sample data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "et_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "et_time = time.clock() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95209999999999995"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.771744000000126"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using RF Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "start = time.clock()\n",
    "\n",
    "\n",
    "#Using the Random Tree Classifier\n",
    "from sklearn import ensemble\n",
    "classifier = ensemble.RandomForestClassifier()\n",
    "\n",
    "#Fit model with sample data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "rf_time = time.clock() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94540000000000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.985648000000083"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using GBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "#Using the Gradient Boosting Tree Classifier\n",
    "start = time.clock()\n",
    "\n",
    "\n",
    "from sklearn import ensemble\n",
    "classifier = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "#Fit model with sample data\n",
    "classifier.fit(train_images, train_target)\n",
    "\n",
    "#Predict Output\n",
    "predicted= classifier.predict(test_images)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gbm_score = accuracy_score(test_target,predicted)\n",
    "\n",
    "gbm_time = time.clock() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94699999999999995"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3993.299466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Deep Learning NN With TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Importing the required library: TensorFlow\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.8\n",
      "step 200, training accuracy 0.94\n",
      "step 300, training accuracy 0.84\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.96\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 0.94\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 0.96\n",
      "step 1300, training accuracy 0.98\n",
      "step 1400, training accuracy 0.94\n",
      "step 1500, training accuracy 0.94\n",
      "step 1600, training accuracy 0.96\n",
      "step 1700, training accuracy 0.96\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 1\n",
      "step 2000, training accuracy 0.98\n",
      "step 2100, training accuracy 1\n",
      "step 2200, training accuracy 0.98\n",
      "step 2300, training accuracy 0.96\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 0.94\n",
      "step 2600, training accuracy 1\n",
      "step 2700, training accuracy 0.98\n",
      "step 2800, training accuracy 0.94\n",
      "step 2900, training accuracy 0.96\n",
      "step 3000, training accuracy 0.94\n",
      "step 3100, training accuracy 0.96\n",
      "step 3200, training accuracy 1\n",
      "step 3300, training accuracy 0.98\n",
      "step 3400, training accuracy 0.98\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 0.98\n",
      "step 3800, training accuracy 1\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.98\n",
      "step 4100, training accuracy 0.96\n",
      "step 4200, training accuracy 1\n",
      "step 4300, training accuracy 0.98\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 0.98\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 0.96\n",
      "step 4800, training accuracy 1\n",
      "step 4900, training accuracy 0.94\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 0.96\n",
      "step 5400, training accuracy 0.98\n",
      "step 5500, training accuracy 0.96\n",
      "step 5600, training accuracy 1\n",
      "step 5700, training accuracy 1\n",
      "step 5800, training accuracy 0.98\n",
      "step 5900, training accuracy 1\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 0.98\n",
      "step 6300, training accuracy 0.98\n",
      "step 6400, training accuracy 1\n",
      "step 6500, training accuracy 0.98\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 1\n",
      "step 7400, training accuracy 1\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 0.98\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 0.98\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 0.98\n",
      "step 9600, training accuracy 0.98\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 1\n",
      "step 10000, training accuracy 1\n",
      "step 10100, training accuracy 1\n",
      "step 10200, training accuracy 1\n",
      "step 10300, training accuracy 1\n",
      "step 10400, training accuracy 1\n",
      "step 10500, training accuracy 1\n",
      "step 10600, training accuracy 1\n",
      "step 10700, training accuracy 1\n",
      "step 10800, training accuracy 1\n",
      "step 10900, training accuracy 0.98\n",
      "step 11000, training accuracy 1\n",
      "step 11100, training accuracy 1\n",
      "step 11200, training accuracy 1\n",
      "step 11300, training accuracy 0.98\n",
      "step 11400, training accuracy 1\n",
      "step 11500, training accuracy 1\n",
      "step 11600, training accuracy 1\n",
      "step 11700, training accuracy 1\n",
      "step 11800, training accuracy 1\n",
      "step 11900, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 12100, training accuracy 1\n",
      "step 12200, training accuracy 1\n",
      "step 12300, training accuracy 0.98\n",
      "step 12400, training accuracy 0.96\n",
      "step 12500, training accuracy 1\n",
      "step 12600, training accuracy 1\n",
      "step 12700, training accuracy 1\n",
      "step 12800, training accuracy 1\n",
      "step 12900, training accuracy 1\n",
      "step 13000, training accuracy 1\n",
      "step 13100, training accuracy 0.98\n",
      "step 13200, training accuracy 1\n",
      "step 13300, training accuracy 1\n",
      "step 13400, training accuracy 1\n",
      "step 13500, training accuracy 1\n",
      "step 13600, training accuracy 0.98\n",
      "step 13700, training accuracy 1\n",
      "step 13800, training accuracy 1\n",
      "step 13900, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 14100, training accuracy 1\n",
      "step 14200, training accuracy 1\n",
      "step 14300, training accuracy 1\n",
      "step 14400, training accuracy 1\n",
      "step 14500, training accuracy 1\n",
      "step 14600, training accuracy 1\n",
      "step 14700, training accuracy 1\n",
      "step 14800, training accuracy 1\n",
      "step 14900, training accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "for i in range(15000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "tf_score = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "\n",
    "tf_time = time.clock() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12861.674889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Deep Learning with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1)\n",
      "55000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "55000/55000 [==============================] - 154s - loss: 2.1336 - acc: 0.2074 - val_loss: 0.6320 - val_acc: 0.8220\n",
      "Epoch 2/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.4897 - acc: 0.8498 - val_loss: 0.2664 - val_acc: 0.9204\n",
      "Epoch 3/200\n",
      "55000/55000 [==============================] - 151s - loss: 0.3536 - acc: 0.8927 - val_loss: 0.2135 - val_acc: 0.9354\n",
      "Epoch 4/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.3083 - acc: 0.9054 - val_loss: 0.1949 - val_acc: 0.9417\n",
      "Epoch 5/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.2791 - acc: 0.9164 - val_loss: 0.1629 - val_acc: 0.9507\n",
      "Epoch 6/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.2533 - acc: 0.9239 - val_loss: 0.1530 - val_acc: 0.9561\n",
      "Epoch 7/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.2399 - acc: 0.9276 - val_loss: 0.1395 - val_acc: 0.9581\n",
      "Epoch 8/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.2289 - acc: 0.9315 - val_loss: 0.1317 - val_acc: 0.9612\n",
      "Epoch 9/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.2137 - acc: 0.9364 - val_loss: 0.1212 - val_acc: 0.9647\n",
      "Epoch 10/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.2028 - acc: 0.9394 - val_loss: 0.1168 - val_acc: 0.9671\n",
      "Epoch 11/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.1906 - acc: 0.9433 - val_loss: 0.1092 - val_acc: 0.9672\n",
      "Epoch 12/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1829 - acc: 0.9451 - val_loss: 0.1010 - val_acc: 0.9691\n",
      "Epoch 13/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.1750 - acc: 0.9480 - val_loss: 0.0963 - val_acc: 0.9699\n",
      "Epoch 14/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1635 - acc: 0.9521 - val_loss: 0.0973 - val_acc: 0.9707\n",
      "Epoch 15/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.1543 - acc: 0.9545 - val_loss: 0.0897 - val_acc: 0.9713\n",
      "Epoch 16/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1463 - acc: 0.9570 - val_loss: 0.0824 - val_acc: 0.9756\n",
      "Epoch 17/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.1398 - acc: 0.9582 - val_loss: 0.0771 - val_acc: 0.9763\n",
      "Epoch 18/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.1347 - acc: 0.9607 - val_loss: 0.0728 - val_acc: 0.9777\n",
      "Epoch 19/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1286 - acc: 0.9617 - val_loss: 0.0696 - val_acc: 0.9787\n",
      "Epoch 20/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.1218 - acc: 0.9645 - val_loss: 0.0674 - val_acc: 0.9786\n",
      "Epoch 21/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.1134 - acc: 0.9672 - val_loss: 0.0633 - val_acc: 0.9797\n",
      "Epoch 22/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1124 - acc: 0.9666 - val_loss: 0.0689 - val_acc: 0.9782\n",
      "Epoch 23/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.1051 - acc: 0.9681 - val_loss: 0.0602 - val_acc: 0.9822\n",
      "Epoch 24/200\n",
      "55000/55000 [==============================] - 150s - loss: 0.1043 - acc: 0.9691 - val_loss: 0.0603 - val_acc: 0.9815\n",
      "Epoch 25/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0996 - acc: 0.9705 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 26/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0944 - acc: 0.9721 - val_loss: 0.0527 - val_acc: 0.9826\n",
      "Epoch 27/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0921 - acc: 0.9728 - val_loss: 0.0526 - val_acc: 0.9822\n",
      "Epoch 28/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0900 - acc: 0.9737 - val_loss: 0.0522 - val_acc: 0.9829\n",
      "Epoch 29/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0849 - acc: 0.9741 - val_loss: 0.0524 - val_acc: 0.9834\n",
      "Epoch 30/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0858 - acc: 0.9754 - val_loss: 0.0526 - val_acc: 0.9830\n",
      "Epoch 31/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0825 - acc: 0.9755 - val_loss: 0.0494 - val_acc: 0.9840\n",
      "Epoch 32/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0795 - acc: 0.9771 - val_loss: 0.0480 - val_acc: 0.9845\n",
      "Epoch 33/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0768 - acc: 0.9776 - val_loss: 0.0467 - val_acc: 0.9851\n",
      "Epoch 34/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0761 - acc: 0.9770 - val_loss: 0.0462 - val_acc: 0.9846\n",
      "Epoch 35/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0750 - acc: 0.9779 - val_loss: 0.0464 - val_acc: 0.9852\n",
      "Epoch 36/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0733 - acc: 0.9780 - val_loss: 0.0443 - val_acc: 0.9854\n",
      "Epoch 37/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0716 - acc: 0.9784 - val_loss: 0.0439 - val_acc: 0.9849\n",
      "Epoch 38/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0710 - acc: 0.9787 - val_loss: 0.0432 - val_acc: 0.9851\n",
      "Epoch 39/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0705 - acc: 0.9793 - val_loss: 0.0436 - val_acc: 0.9848\n",
      "Epoch 40/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0698 - acc: 0.9791 - val_loss: 0.0421 - val_acc: 0.9861\n",
      "Epoch 41/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0678 - acc: 0.9798 - val_loss: 0.0464 - val_acc: 0.9845\n",
      "Epoch 42/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0660 - acc: 0.9803 - val_loss: 0.0420 - val_acc: 0.9861\n",
      "Epoch 43/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0652 - acc: 0.9804 - val_loss: 0.0444 - val_acc: 0.9866\n",
      "Epoch 44/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0658 - acc: 0.9802 - val_loss: 0.0420 - val_acc: 0.9861\n",
      "Epoch 45/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0643 - acc: 0.9801 - val_loss: 0.0430 - val_acc: 0.9861\n",
      "Epoch 46/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0638 - acc: 0.9805 - val_loss: 0.0409 - val_acc: 0.9862\n",
      "Epoch 47/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0627 - acc: 0.9815 - val_loss: 0.0413 - val_acc: 0.9865\n",
      "Epoch 48/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0622 - acc: 0.9813 - val_loss: 0.0399 - val_acc: 0.9867\n",
      "Epoch 49/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0631 - acc: 0.9816 - val_loss: 0.0424 - val_acc: 0.9863\n",
      "Epoch 50/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0633 - acc: 0.9813 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "Epoch 51/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0612 - acc: 0.9816 - val_loss: 0.0390 - val_acc: 0.9879\n",
      "Epoch 52/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0621 - acc: 0.9822 - val_loss: 0.0379 - val_acc: 0.9871\n",
      "Epoch 53/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0590 - acc: 0.9825 - val_loss: 0.0412 - val_acc: 0.9868\n",
      "Epoch 54/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0604 - acc: 0.9819 - val_loss: 0.0396 - val_acc: 0.9871\n",
      "Epoch 55/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0591 - acc: 0.9824 - val_loss: 0.0389 - val_acc: 0.9870\n",
      "Epoch 56/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0596 - acc: 0.9821 - val_loss: 0.0419 - val_acc: 0.9871\n",
      "Epoch 57/200\n",
      "55000/55000 [==============================] - 151s - loss: 0.0591 - acc: 0.9825 - val_loss: 0.0388 - val_acc: 0.9875\n",
      "Epoch 58/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0580 - acc: 0.9821 - val_loss: 0.0381 - val_acc: 0.9869\n",
      "Epoch 59/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0598 - acc: 0.9819 - val_loss: 0.0383 - val_acc: 0.9878\n",
      "Epoch 60/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0555 - acc: 0.9834 - val_loss: 0.0401 - val_acc: 0.9873\n",
      "Epoch 61/200\n",
      "55000/55000 [==============================] - 145s - loss: 0.0570 - acc: 0.9832 - val_loss: 0.0393 - val_acc: 0.9872\n",
      "Epoch 62/200\n",
      "55000/55000 [==============================] - 150s - loss: 0.0582 - acc: 0.9824 - val_loss: 0.0403 - val_acc: 0.9875\n",
      "Epoch 63/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0552 - acc: 0.9832 - val_loss: 0.0392 - val_acc: 0.9871\n",
      "Epoch 64/200\n",
      "55000/55000 [==============================] - 145s - loss: 0.0561 - acc: 0.9828 - val_loss: 0.0394 - val_acc: 0.9873\n",
      "Epoch 65/200\n",
      "55000/55000 [==============================] - 145s - loss: 0.0551 - acc: 0.9834 - val_loss: 0.0385 - val_acc: 0.9873\n",
      "Epoch 66/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.0549 - acc: 0.9831 - val_loss: 0.0388 - val_acc: 0.9869\n",
      "Epoch 67/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0572 - acc: 0.9839 - val_loss: 0.0370 - val_acc: 0.9883\n",
      "Epoch 68/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0554 - acc: 0.9832 - val_loss: 0.0384 - val_acc: 0.9870\n",
      "Epoch 69/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0554 - acc: 0.9839 - val_loss: 0.0375 - val_acc: 0.9877\n",
      "Epoch 70/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0549 - acc: 0.9841 - val_loss: 0.0381 - val_acc: 0.9882\n",
      "Epoch 71/200\n",
      "55000/55000 [==============================] - 150s - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0371 - val_acc: 0.9879\n",
      "Epoch 72/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0560 - acc: 0.9837 - val_loss: 0.0390 - val_acc: 0.9884\n",
      "Epoch 73/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0551 - acc: 0.9835 - val_loss: 0.0378 - val_acc: 0.9875\n",
      "Epoch 74/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0536 - acc: 0.9839 - val_loss: 0.0370 - val_acc: 0.9872\n",
      "Epoch 75/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0546 - acc: 0.9841 - val_loss: 0.0369 - val_acc: 0.9878\n",
      "Epoch 76/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0533 - acc: 0.9845 - val_loss: 0.0411 - val_acc: 0.9871\n",
      "Epoch 77/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0551 - acc: 0.9840 - val_loss: 0.0401 - val_acc: 0.9874\n",
      "Epoch 78/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0524 - acc: 0.9839 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "Epoch 79/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0535 - acc: 0.9835 - val_loss: 0.0373 - val_acc: 0.9878\n",
      "Epoch 80/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0533 - acc: 0.9839 - val_loss: 0.0373 - val_acc: 0.9883\n",
      "Epoch 81/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0531 - acc: 0.9837 - val_loss: 0.0369 - val_acc: 0.9879\n",
      "Epoch 82/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0519 - acc: 0.9844 - val_loss: 0.0374 - val_acc: 0.9879\n",
      "Epoch 83/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0530 - acc: 0.9839 - val_loss: 0.0367 - val_acc: 0.9881\n",
      "Epoch 84/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0541 - acc: 0.9839 - val_loss: 0.0365 - val_acc: 0.9884\n",
      "Epoch 85/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0545 - acc: 0.9841 - val_loss: 0.0361 - val_acc: 0.9885\n",
      "Epoch 86/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0553 - acc: 0.9839 - val_loss: 0.0350 - val_acc: 0.9891\n",
      "Epoch 87/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0538 - acc: 0.9838 - val_loss: 0.0377 - val_acc: 0.9873\n",
      "Epoch 88/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0546 - acc: 0.9838 - val_loss: 0.0365 - val_acc: 0.9894\n",
      "Epoch 89/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0539 - acc: 0.9846 - val_loss: 0.0356 - val_acc: 0.9891\n",
      "Epoch 90/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0534 - acc: 0.9830 - val_loss: 0.0374 - val_acc: 0.9886\n",
      "Epoch 91/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0545 - acc: 0.9842 - val_loss: 0.0372 - val_acc: 0.9888\n",
      "Epoch 92/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0554 - acc: 0.9835 - val_loss: 0.0360 - val_acc: 0.9881\n",
      "Epoch 93/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.0520 - acc: 0.9845 - val_loss: 0.0357 - val_acc: 0.9891\n",
      "Epoch 94/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0521 - acc: 0.9845 - val_loss: 0.0367 - val_acc: 0.9883\n",
      "Epoch 95/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0527 - acc: 0.9837 - val_loss: 0.0375 - val_acc: 0.9882\n",
      "Epoch 96/200\n",
      "55000/55000 [==============================] - 163s - loss: 0.0512 - acc: 0.9844 - val_loss: 0.0411 - val_acc: 0.9885\n",
      "Epoch 97/200\n",
      "55000/55000 [==============================] - 166s - loss: 0.0533 - acc: 0.9843 - val_loss: 0.0371 - val_acc: 0.9884\n",
      "Epoch 98/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0523 - acc: 0.9849 - val_loss: 0.0380 - val_acc: 0.9884\n",
      "Epoch 99/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0539 - acc: 0.9839 - val_loss: 0.0372 - val_acc: 0.9895\n",
      "Epoch 100/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0533 - acc: 0.9840 - val_loss: 0.0370 - val_acc: 0.9887\n",
      "Epoch 101/200\n",
      "55000/55000 [==============================] - 164s - loss: 0.0537 - acc: 0.9836 - val_loss: 0.0369 - val_acc: 0.9882\n",
      "Epoch 102/200\n",
      "55000/55000 [==============================] - 163s - loss: 0.0543 - acc: 0.9838 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 103/200\n",
      "55000/55000 [==============================] - 168s - loss: 0.0535 - acc: 0.9847 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 104/200\n",
      "55000/55000 [==============================] - 168s - loss: 0.0525 - acc: 0.9845 - val_loss: 0.0367 - val_acc: 0.9884\n",
      "Epoch 105/200\n",
      "55000/55000 [==============================] - 167s - loss: 0.0543 - acc: 0.9834 - val_loss: 0.0367 - val_acc: 0.9878\n",
      "Epoch 106/200\n",
      "55000/55000 [==============================] - 167s - loss: 0.0527 - acc: 0.9845 - val_loss: 0.0372 - val_acc: 0.9894\n",
      "Epoch 107/200\n",
      "55000/55000 [==============================] - 161s - loss: 0.0530 - acc: 0.9845 - val_loss: 0.0437 - val_acc: 0.9876\n",
      "Epoch 108/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0513 - acc: 0.9847 - val_loss: 0.0362 - val_acc: 0.9885\n",
      "Epoch 109/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0512 - acc: 0.9846 - val_loss: 0.0365 - val_acc: 0.9885\n",
      "Epoch 110/200\n",
      "55000/55000 [==============================] - 159s - loss: 0.0505 - acc: 0.9846 - val_loss: 0.0361 - val_acc: 0.9894\n",
      "Epoch 111/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0534 - acc: 0.9845 - val_loss: 0.0413 - val_acc: 0.9877\n",
      "Epoch 112/200\n",
      "55000/55000 [==============================] - 164s - loss: 0.0523 - acc: 0.9842 - val_loss: 0.0359 - val_acc: 0.9886\n",
      "Epoch 113/200\n",
      "55000/55000 [==============================] - 165s - loss: 0.0507 - acc: 0.9847 - val_loss: 0.0382 - val_acc: 0.9885\n",
      "Epoch 114/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0531 - acc: 0.9843 - val_loss: 0.0378 - val_acc: 0.9885\n",
      "Epoch 115/200\n",
      "55000/55000 [==============================] - 168s - loss: 0.0504 - acc: 0.9845 - val_loss: 0.0360 - val_acc: 0.9890\n",
      "Epoch 116/200\n",
      "55000/55000 [==============================] - 174s - loss: 0.0519 - acc: 0.9846 - val_loss: 0.0381 - val_acc: 0.9876\n",
      "Epoch 117/200\n",
      "55000/55000 [==============================] - 174s - loss: 0.0529 - acc: 0.9842 - val_loss: 0.0390 - val_acc: 0.9883\n",
      "Epoch 118/200\n",
      "55000/55000 [==============================] - 171s - loss: 0.0518 - acc: 0.9843 - val_loss: 0.0367 - val_acc: 0.9891\n",
      "Epoch 119/200\n",
      "55000/55000 [==============================] - 171s - loss: 0.0515 - acc: 0.9847 - val_loss: 0.0368 - val_acc: 0.9893\n",
      "Epoch 120/200\n",
      "55000/55000 [==============================] - 173s - loss: 0.0513 - acc: 0.9845 - val_loss: 0.0356 - val_acc: 0.9894\n",
      "Epoch 121/200\n",
      "55000/55000 [==============================] - 172s - loss: 0.0517 - acc: 0.9850 - val_loss: 0.0357 - val_acc: 0.9897\n",
      "Epoch 122/200\n",
      "55000/55000 [==============================] - 166s - loss: 0.0520 - acc: 0.9839 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "Epoch 123/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0518 - acc: 0.9841 - val_loss: 0.0358 - val_acc: 0.9900\n",
      "Epoch 124/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0521 - acc: 0.9849 - val_loss: 0.0375 - val_acc: 0.9884\n",
      "Epoch 125/200\n",
      "55000/55000 [==============================] - 163s - loss: 0.0519 - acc: 0.9845 - val_loss: 0.0363 - val_acc: 0.9890\n",
      "Epoch 126/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0507 - acc: 0.9850 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 127/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0513 - acc: 0.9845 - val_loss: 0.0370 - val_acc: 0.9892\n",
      "Epoch 128/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0488 - acc: 0.9854 - val_loss: 0.0381 - val_acc: 0.9887\n",
      "Epoch 129/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0499 - acc: 0.9850 - val_loss: 0.0383 - val_acc: 0.9885\n",
      "Epoch 130/200\n",
      "55000/55000 [==============================] - 194s - loss: 0.0520 - acc: 0.9852 - val_loss: 0.0362 - val_acc: 0.9891\n",
      "Epoch 131/200\n",
      "55000/55000 [==============================] - 180s - loss: 0.0495 - acc: 0.9852 - val_loss: 0.0364 - val_acc: 0.9890\n",
      "Epoch 132/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0511 - acc: 0.9840 - val_loss: 0.0362 - val_acc: 0.9895\n",
      "Epoch 133/200\n",
      "55000/55000 [==============================] - 161s - loss: 0.0498 - acc: 0.9856 - val_loss: 0.0374 - val_acc: 0.9891\n",
      "Epoch 134/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0507 - acc: 0.9850 - val_loss: 0.0358 - val_acc: 0.9885\n",
      "Epoch 135/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0484 - acc: 0.9858 - val_loss: 0.0341 - val_acc: 0.9887\n",
      "Epoch 136/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0483 - acc: 0.9853 - val_loss: 0.0351 - val_acc: 0.9892\n",
      "Epoch 137/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0492 - acc: 0.9844 - val_loss: 0.0329 - val_acc: 0.9893\n",
      "Epoch 138/200\n",
      "55000/55000 [==============================] - 164s - loss: 0.0502 - acc: 0.9851 - val_loss: 0.0385 - val_acc: 0.9891\n",
      "Epoch 139/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0494 - acc: 0.9852 - val_loss: 0.0385 - val_acc: 0.9891\n",
      "Epoch 140/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0511 - acc: 0.9849 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "Epoch 141/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0500 - acc: 0.9845 - val_loss: 0.0356 - val_acc: 0.9887\n",
      "Epoch 142/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0489 - acc: 0.9856 - val_loss: 0.0353 - val_acc: 0.9900\n",
      "Epoch 143/200\n",
      "55000/55000 [==============================] - 159s - loss: 0.0485 - acc: 0.9859 - val_loss: 0.0363 - val_acc: 0.9895\n",
      "Epoch 144/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0494 - acc: 0.9851 - val_loss: 0.0400 - val_acc: 0.9885\n",
      "Epoch 145/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.0523 - acc: 0.9848 - val_loss: 0.0413 - val_acc: 0.9880\n",
      "Epoch 146/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0488 - acc: 0.9850 - val_loss: 0.0430 - val_acc: 0.9877\n",
      "Epoch 147/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0487 - acc: 0.9857 - val_loss: 0.0376 - val_acc: 0.9890\n",
      "Epoch 148/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0491 - acc: 0.9853 - val_loss: 0.0370 - val_acc: 0.9886\n",
      "Epoch 149/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0369 - val_acc: 0.9896\n",
      "Epoch 150/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0504 - acc: 0.9850 - val_loss: 0.0343 - val_acc: 0.9897\n",
      "Epoch 151/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.0489 - acc: 0.9853 - val_loss: 0.0385 - val_acc: 0.9883\n",
      "Epoch 152/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0499 - acc: 0.9858 - val_loss: 0.0350 - val_acc: 0.9898\n",
      "Epoch 153/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0496 - acc: 0.9852 - val_loss: 0.0356 - val_acc: 0.9899\n",
      "Epoch 154/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0480 - acc: 0.9850 - val_loss: 0.0415 - val_acc: 0.9885\n",
      "Epoch 155/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0499 - acc: 0.9851 - val_loss: 0.0365 - val_acc: 0.9894\n",
      "Epoch 156/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0487 - acc: 0.9851 - val_loss: 0.0351 - val_acc: 0.9902\n",
      "Epoch 157/200\n",
      "55000/55000 [==============================] - 147s - loss: 0.0481 - acc: 0.9856 - val_loss: 0.0348 - val_acc: 0.9891\n",
      "Epoch 158/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0485 - acc: 0.9856 - val_loss: 0.0350 - val_acc: 0.9897\n",
      "Epoch 159/200\n",
      "55000/55000 [==============================] - 151s - loss: 0.0463 - acc: 0.9858 - val_loss: 0.0379 - val_acc: 0.9898\n",
      "Epoch 160/200\n",
      "55000/55000 [==============================] - 150s - loss: 0.0477 - acc: 0.9861 - val_loss: 0.0352 - val_acc: 0.9904\n",
      "Epoch 161/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0450 - acc: 0.9864 - val_loss: 0.0372 - val_acc: 0.9901\n",
      "Epoch 162/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0499 - acc: 0.9851 - val_loss: 0.0358 - val_acc: 0.9899\n",
      "Epoch 163/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0491 - acc: 0.9855 - val_loss: 0.0350 - val_acc: 0.9885\n",
      "Epoch 164/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0488 - acc: 0.9855 - val_loss: 0.0353 - val_acc: 0.9905\n",
      "Epoch 165/200\n",
      "55000/55000 [==============================] - 161s - loss: 0.0458 - acc: 0.9857 - val_loss: 0.0365 - val_acc: 0.9894\n",
      "Epoch 166/200\n",
      "55000/55000 [==============================] - 151s - loss: 0.0473 - acc: 0.9859 - val_loss: 0.0355 - val_acc: 0.9896\n",
      "Epoch 167/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0481 - acc: 0.9855 - val_loss: 0.0354 - val_acc: 0.9899\n",
      "Epoch 168/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0452 - acc: 0.9866 - val_loss: 0.0368 - val_acc: 0.9887\n",
      "Epoch 169/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0486 - acc: 0.9854 - val_loss: 0.0328 - val_acc: 0.9897\n",
      "Epoch 170/200\n",
      "55000/55000 [==============================] - 153s - loss: 0.0466 - acc: 0.9867 - val_loss: 0.0344 - val_acc: 0.9887\n",
      "Epoch 171/200\n",
      "55000/55000 [==============================] - 154s - loss: 0.0470 - acc: 0.9860 - val_loss: 0.0368 - val_acc: 0.9891\n",
      "Epoch 172/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0448 - acc: 0.9862 - val_loss: 0.0348 - val_acc: 0.9887\n",
      "Epoch 179/200\n",
      "55000/55000 [==============================] - 152s - loss: 0.0465 - acc: 0.9859 - val_loss: 0.0356 - val_acc: 0.9898\n",
      "Epoch 180/200\n",
      "55000/55000 [==============================] - 160s - loss: 0.0481 - acc: 0.9852 - val_loss: 0.0360 - val_acc: 0.9880\n",
      "Epoch 181/200\n",
      "55000/55000 [==============================] - 158s - loss: 0.0471 - acc: 0.9858 - val_loss: 0.0383 - val_acc: 0.9888\n",
      "Epoch 182/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0466 - acc: 0.9865 - val_loss: 0.0339 - val_acc: 0.9905\n",
      "Epoch 183/200\n",
      "55000/55000 [==============================] - 161s - loss: 0.0456 - acc: 0.9861 - val_loss: 0.0333 - val_acc: 0.9897\n",
      "Epoch 184/200\n",
      "55000/55000 [==============================] - 162s - loss: 0.0447 - acc: 0.9865 - val_loss: 0.0330 - val_acc: 0.9895\n",
      "Epoch 185/200\n",
      "55000/55000 [==============================] - 159s - loss: 0.0438 - acc: 0.9870 - val_loss: 0.0360 - val_acc: 0.9897\n",
      "Epoch 187/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0438 - acc: 0.9871 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 188/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0461 - acc: 0.9857 - val_loss: 0.0352 - val_acc: 0.9898\n",
      "Epoch 189/200\n",
      "55000/55000 [==============================] - 157s - loss: 0.0472 - acc: 0.9854 - val_loss: 0.0341 - val_acc: 0.9904\n",
      "Epoch 190/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0456 - acc: 0.9860 - val_loss: 0.0338 - val_acc: 0.9897\n",
      "Epoch 191/200\n",
      "55000/55000 [==============================] - 155s - loss: 0.0432 - acc: 0.9869 - val_loss: 0.0362 - val_acc: 0.9901\n",
      "Epoch 192/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0465 - acc: 0.9867 - val_loss: 0.0412 - val_acc: 0.9884\n",
      "Epoch 193/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0456 - acc: 0.9860 - val_loss: 0.0371 - val_acc: 0.9888\n",
      "Epoch 194/200\n",
      "55000/55000 [==============================] - 156s - loss: 0.0457 - acc: 0.9863 - val_loss: 0.0332 - val_acc: 0.9891\n",
      "Epoch 195/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0475 - acc: 0.9857 - val_loss: 0.0330 - val_acc: 0.9899\n",
      "Epoch 196/200\n",
      "55000/55000 [==============================] - 145s - loss: 0.0459 - acc: 0.9863 - val_loss: 0.0343 - val_acc: 0.9888\n",
      "Epoch 197/200\n",
      "55000/55000 [==============================] - 146s - loss: 0.0435 - acc: 0.9868 - val_loss: 0.0372 - val_acc: 0.9892\n",
      "Epoch 198/200\n",
      "55000/55000 [==============================] - 148s - loss: 0.0414 - acc: 0.9880 - val_loss: 0.0358 - val_acc: 0.9887\n",
      "Epoch 199/200\n",
      "55000/55000 [==============================] - 149s - loss: 0.0436 - acc: 0.9869 - val_loss: 0.0355 - val_acc: 0.9896\n",
      "Epoch 200/200\n",
      "55000/55000 [==============================] - 151s - loss: 0.0438 - acc: 0.9869 - val_loss: 0.0336 - val_acc: 0.9904\n"
     ]
    }
   ],
   "source": [
    "start = time.clock()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "ke_score = score[1]\n",
    "\n",
    "ke_time = time.clock() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99039999999999995"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ke_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184656.268011"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ke_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing the Accuracies of various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scores = [knn_score, svm_score, dt_score,  et_score, rf_score, gbm_score, tf_score, ke_score]\n",
    "\n",
    "#Converting to percentage\n",
    "scores = scores*np.array(100)\n",
    "names = ['KNN', 'SVM', 'DT', 'ET', 'RF', 'GBM', 'TF', 'Ke']\n",
    "\n",
    "dat = pd.DataFrame({'Algorithms':names, 'Accuracy':scores})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0cAAAGFCAYAAAA2BYgVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCUcAQAAVMIRAABAVf8/AVodPSJrQUEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefb0ccde80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(x=\"Algorithms\", y=\"Accuracy\", data=dat)\n",
    "plt.ylabel('Accuracy (in %)', fontsize=12)\n",
    "plt.xlabel('Algorithms', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comparing the Training Times of various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "times = [knn_time, svm_time, dt_time, et_time, rf_time, gbm_time, tf_time, ke_time]\n",
    "names = ['KNN', 'SVM', 'DT', 'ET', 'RF', 'GBM', 'TF', 'Ke']\n",
    "\n",
    "\n",
    "names = ['KNN', 'SVM', 'DT', 'ET', 'RF', 'GBM', 'TF', 'Ke']\n",
    "\n",
    "dat = pd.DataFrame({'Algorithms':names, 'Time':times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAGFCAYAAADkVYJNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xtc1HW+x/H3CKjE4RKKI4JR4cN0y0upJaKYl0BQVDIz\nS9NotY6rtiZ2vIWiYbtd1N3VU+iaZW1rKwpmgvdt0/WWVId087iS6a6XEWM1QVcU5vzhw9+JVdxJ\nv8M08Ho+Hj4ezO/3m+EzjMK8/F2wOZ1OpwAAAAAAxtTz9AAAAAAAUNsQWgAAAABgGKEFAAAAAIYR\nWgAAAABgGKEFAAAAAIYRWgAAAABgWI2F1okTJ/Tkk0+qb9++Sk5O1rJlyyRJZ86cUWpqqhISEvT0\n00/r7Nmz1n2ysrIUHx+vxMREbdu2zVq+b98+JScnKyEhQZmZmdby8vJyTZgwQfHx8RoyZIiOHTtm\nrcvJyVFCQoISEhKUm5tbA88YAAAAQF1VY6Hl4+OjKVOmaO3atVq+fLl+97vfqaioSIsWLVJMTIzW\nr1+vBx54QFlZWZKkgwcPKj8/X3l5eVq8eLEyMjJ05Vd+zZw5U5mZmVq/fr2++eYbbd26VZKUnZ2t\n4OBgbdiwQSNGjNCrr74q6XLMLVy4UNnZ2VqxYoUWLFhQJegAAAAAwKQaC62wsDC1bt1akhQQEKDo\n6Gg5HA5t3rxZKSkpkqSUlBRt2rRJkrRlyxYlJSXJ19dXkZGRioqKUmFhoYqLi1VWVqa2bdtKkgYO\nHGjd5/uPlZCQoJ07d0qStm3bptjYWAUGBiooKEixsbFWnAEAAACAaR45R+vvf/+79u/fr3bt2unb\nb79V48aNJV2OsZKSEkmSw+FQeHi4dR+73S6HwyGHw6GmTZtetVySTp48aa3z8fFRYGCgTp8+Xe1j\nAQAAAIA71HholZWVafz48Zo6daoCAgJks9mqrP/X2zfjyqGGAAAAAFCTfGvyk126dEnjx4/XgAED\n1Lt3b0lSo0aNdOrUKTVu3FjFxcUKDQ2VdHmv0/Hjx637njhxQna7/arlDodDdrtdktSkSRNru4qK\nCpWWliokJER2u127du2q8lidO3e+7qwFBQXGnjcAAACA2qtDhw5XLavR0Jo6dapatGihESNGWMt6\n9uypVatWafTo0crJyVGvXr2s5WlpaRo5cqQcDoeOHDmitm3bymazKTAwUIWFhWrTpo1yc3M1fPhw\n6z45OTlq166d1q1bZ8VU165dNW/ePJ09e1aVlZXavn270tLS/u281/qCAQAAAMAV1e2gqbHQKigo\n0Jo1a9SyZUsNHDhQNptNEyZM0KhRo/Tzn/9cK1euVEREhObPny9JatGihRITE9W3b1/5+vpqxowZ\n1mGF6enpmjJlii5cuKC4uDjFxcVJkgYPHqxJkyYpPj5eISEhmjt3riQpODhYY8aM0aBBg2Sz2TR2\n7FgFBQXV1FMHAAAAUMfYnJzIdE0FBQXs0QIAAABwXdV1g0euOggAAAAAtRmhBQAAAACGEVoAAAAA\nYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoA\nAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACG\nEVoAAAAAYBihBQAAAACGEVoAAAAAYJivpwcAAAAA4B4VFRUqKiry9BheKTo6Wj4+Pjd8f0ILAAAA\nqKWKiopU8Nonui00wtOjeJUjJUelNKlly5Y3/BiEFgAAAFCL3RYaoeiwOzw9Rp3DOVoAAAAAYBih\nBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAA\nYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoA\nAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACG\nEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAA\nAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBih\nBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAA\nYBihBQAAAACGEVoAAAAAYBihBQAAAACGEVoAAAAAYFiNhdbUqVPVpUsXJScnW8sWLFiguLg4paSk\nKCUlRZ988om1LisrS/Hx8UpMTNS2bdus5fv27VNycrISEhKUmZlpLS8vL9eECRMUHx+vIUOG6Nix\nY9a6nJwcJSQkKCEhQbm5uW5+pgAAAADquhoLrYcfflhLliy5avlTTz2lnJwc5eTkKC4uTpJUVFSk\n/Px85eXlafHixcrIyJDT6ZQkzZw5U5mZmVq/fr2++eYbbd26VZKUnZ2t4OBgbdiwQSNGjNCrr74q\nSTpz5owWLlyo7OxsrVixQgsWLNDZs2dr6FkDAAAAqItqLLQ6duyooKCgq5ZfCajv27x5s5KSkuTr\n66vIyEhFRUWpsLBQxcXFKisrU9u2bSVJAwcO1KZNm6z7pKSkSJISEhK0c+dOSdK2bdsUGxurwMBA\nBQUFKTY21oozAAAAAHAHj5+j9d5772nAgAGaNm2atafJ4XAoPDzc2sZut8vhcMjhcKhp06ZXLZek\nkydPWut8fHwUGBio06dPV/tYAAAAAOAuHg2txx9/XJs3b9bq1avVuHFj/eIXvzD22NfaUwYAAAAA\nNcHXk588NDTU+vjRRx/Vs88+K+nyXqfjx49b606cOCG73X7VcofDIbvdLklq0qSJtV1FRYVKS0sV\nEhIiu92uXbt2VXmszp07uzRfQUHBTT0/AAAAwJMOHz4su/w9PYZX2rt3701d26FGQ+tf9zIVFxcr\nLCxMkrRx40a1bNlSktSzZ0+lpaVp5MiRcjgcOnLkiNq2bSubzabAwEAVFhaqTZs2ys3N1fDhw637\n5OTkqF27dlq3bp0VU127dtW8efN09uxZVVZWavv27UpLS3Np3g4dOph66gAAAECNCwwMVPHuIk+P\n4ZXuueceq0+up7qdMzUWWhMnTtSuXbt0+vRpPfjggxo3bpx27dqlr776SvXq1VNERIRmzZolSWrR\nooUSExPVt29f+fr6asaMGbLZbJKk9PR0TZkyRRcuXFBcXJx1pcLBgwdr0qRJio+PV0hIiObOnStJ\nCg4O1pgxYzRo0CDZbDaNHTv2mhflAAAAAABTbE5OZrqmgoIC9mgBAADAqx04cEDFbxUpOuwOT4/i\nVYqKDyksNdrlPVrX6gaPX3UQAAAAAGobQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsA\nAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAw\nQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAA\nAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0\nAAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAA\nDCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwQgsAAAAADCO0AAAAAMAwX1c2unjxog4dOqTvvvtOQUFB\nuuOOO+Tn5+fu2QAAAADAK103tD7++GMtX75cO3bskK+vrwICAlRWVqZLly6pc+fOeuyxx9SjR4+a\nmhUAAAAAvEK1ofXYY48pODhY/fr1U0ZGhux2u7XO4XDo008/1fLly5WVlaXly5fXyLAAAAAA4A2q\nDa2MjAzddddd11xnt9vVr18/9evXT//7v//rtuEAAAAAwBtVezGM6iLrRrcDAAAAgLrCpasOjh07\nVnv27KmybM+ePRo/frxbhgIAAAAAb+ZSaH366ae69957qyxr3769du3a5ZahAAAAAMCbuRRa9evX\n1/nz56ssO3funHx9Xbo6PAAAAADUKS6FVteuXZWenq7S0lJJUmlpqWbNmqVu3bq5dTgAAAAA8EYu\nhdbkyZNVWlqqTp06KSYmRvfff79KS0s1depUd88HAAAAAF7HpWP/goODtWjRIhUXF+v48eMKDw9X\nWFiYu2cDAAAAAK/k0h4tSfrHP/6hP//5z9q1a5fCwsLkcDh04sQJd84GAAAAAF7JpdDavXu3+vTp\nozVr1ui///u/JUmHDx/WzJkz3TkbAAAAAHgll0Jrzpw5mj9/vpYsWWJdabBdu3YqLCx063AAAAAA\n4I1cCq2jR48qJiZGkmSz2SRJfn5+qqiocN9kAAAAAOClXAqt6Ohobd26tcqy7du3q2XLlm4ZCgAA\nAAC8mUtXHZw8ebKeeeYZPfjgg/rnP/+p9PR0bdmyxTpfCwAAAADw/1zao9W+fXt9+OGHatGihQYN\nGqTIyEhlZ2erbdu27p4PAAAAALyOS3u0JMlut2vUqFGSpDNnzig4ONhtQwEAAACAN7vuHq3c3Nwq\n52bt3btX3bt3V+fOnZWQkKCvv/7a7QMCAAAAgLe5bmgtWbJEYWFh1u3p06erS5cu+vDDD9WlSxe9\n8sorbh8QAAAAALzNdQ8dPHHihHVlwePHj+uvf/2r3n77bYWEhGjixImKj4+vkSEBAAAAwJtcd4+W\nj4+PLl68KEn6/PPPdeeddyokJESS5O/vr3/+85/unxAAAAAAvMx1Q+v+++/XvHnztH//fr377rvq\n0aOHte7rr7+uclghAAAAAOCy64bWtGnT9Je//EVDhw6Vv7+/ddVBSVq9erW6devm9gEBAAAAwNtc\n9xwtu92uZcuWXXNdWlqaWwYCAAAAAG/n0i8sBgAAAAC4jtACAAAAAMMILQAAAAAwjNACAAAAAMOu\nezGM7/v666+1f/9+nTt3rsryRx55xPhQAAAAAODNXAqtN998UwsXLlSrVq3UsGFDa7nNZiO0AAAA\nAOBfuBRa77zzjlasWKFWrVq5ex4AAAAA8HounaPVsGFD3Xnnne6eBQAAAABqBZdC67nnntNLL72k\nkydPqrKyssofV02dOlVdunRRcnKytezMmTNKTU1VQkKCnn76aZ09e9Zal5WVpfj4eCUmJmrbtm3W\n8n379ik5OVkJCQnKzMy0lpeXl2vChAmKj4/XkCFDdOzYMWtdTk6OEhISlJCQoNzcXJdnBgAAAIAb\n4VJoTZ48WX/4wx/UvXt33X333br77rv1k5/8RHfffbfLn+jhhx/WkiVLqixbtGiRYmJitH79ej3w\nwAPKysqSJB08eFD5+fnKy8vT4sWLlZGRIafTKUmaOXOmMjMztX79en3zzTfaunWrJCk7O1vBwcHa\nsGGDRowYoVdffVXS5ZhbuHChsrOztWLFCi1YsKBK0AEAAACAaS6do7V58+ab/kQdO3bU0aNHr3rc\n9957T5KUkpKi4cOHKy0tTVu2bFFSUpJ8fX0VGRmpqKgoFRYWqlmzZiorK1Pbtm0lSQMHDtSmTZvU\nrVs3bd68WePHj5ckJSQkaPbs2ZKkbdu2KTY2VoGBgZKk2NhYbd26VUlJSTf9nAAAAADgWlwKrYiI\nCLd88pKSEjVu3FiSFBYWppKSEkmSw+FQ+/btre3sdrscDod8fHzUtGnTq5ZL0smTJ611Pj4+CgwM\n1OnTp+VwOBQeHn7N+wAAAACAO1QbWi+++KK1V2jSpEmy2WzX3O6VV14xNkx1n+NGXDnU8GYUFBQY\nmAQAAADwjMOHD8suf0+P4ZX27t17U6ccVRtakZGR1sdRUVE3/Amup1GjRjp16pQaN26s4uJihYaG\nSrq81+n48ePWdidOnJDdbr9qucPhkN1ulyQ1adLE2q6iokKlpaUKCQmR3W7Xrl27qjxW586dXZqv\nQ4cOJp4mAAAA4BGBgYEq3l3k6TG80j333KOWLVv+2+2q2zlTbWg988wz1sdjx469gdGu9q97mXr2\n7KlVq1Zp9OjRysnJUa9evazlaWlpGjlypBwOh44cOaK2bdvKZrMpMDBQhYWFatOmjXJzczV8+HDr\nPjk5OWrXrp3WrVtnxVTXrl01b948nT17VpWVldq+fbvS0tKMPB8AAAAAuJZqQ2v//v0u/YJiV7eb\nOHGidu3apdOnT+vBBx/UuHHjNHr0aD333HNauXKlIiIiNH/+fElSixYtlJiYqL59+8rX11czZsyw\nDitMT0/XlClTdOHCBcXFxSkuLk6SNHjwYE2aNEnx8fEKCQnR3LlzJUnBwcEaM2aMBg0aJJvNprFj\nxyooKOjff2UAAAAA4AbZnNWczDR06FD9x3/8hwYMGKBOnTpZh+hJly888emnnyo3N1dlZWV6//33\na2zgmlJQUMChgwAAAPBqBw4cUPFbRYoOu8PTo3iVouJDCkuNdvnQwWt1Q7V7tH7/+9/rj3/8o5Yv\nX65p06apXr16CggIUFlZmSQpJiZGw4YNU/fu3W/iKQAAAABA7XPdy7v36NFDPXr00MWLF3X48GF9\n9913Cg4O1m233SY/P7+amhEAAAAAvIpLv0fLz89PLVq0cPcsAAAAAFAr1PP0AAAAAABQ2xBaAAAA\nAGAYoQUAAAAAhv2g0Dp+/Li++OILd80CAAAAALWCS6F17NgxPfbYY0pMTNRTTz0lSVq3bp2mTZvm\n1uEAAAAAwBu5FFrp6el68MEH9dlnn8nX9/KFCmNjY7V9+3a3DgcAAAAA3sil0Pryyy81evRo1atX\nTzabTZIUGBios2fPunU4AAAAAPBGLoVWo0aNdPjw4SrLDh48qPDwcLcMBQAAAADezKXQSk1N1bPP\nPquVK1fq0qVL+uijjzRhwgSNGjXK3fMBAAAAgNfxdWWjRx55RCEhIfrggw8UHh6unJwcPffcc+rd\nu7e75wMAAAAAr+NSaElS7969CSsAAAAAcIHLobVnzx795S9/0blz56osf/bZZ40PBQAAAADezKXQ\nmj17tvLz89WxY0c1aNDAWn7lCoQAAAAAgP/nUmitWbNGa9askd1ud/c8AAAAAOD1XLrqYNOmTVW/\nfn13zwIAAAAAtYJLe7QyMzM1ffp0JScnq1GjRlXWderUyS2DAQAAAIC3cim09u7dq08++UR79uxR\nw4YNreU2m00ff/yxu2YDAAAAAK/kUmjNnz9fb775pmJjY909DwAAAAB4PZfO0fL39+cQQQAAAABw\nkUuhNX78eM2ZM0fFxcWqrKys8gcAAAAAUJVLhw5OnTpVkvTBBx9Yy5xOp2w2m7766iv3TAYAAAAA\nXsql0Nq8ebO75wAAAACAWsOl0IqIiHD3HAAAAABQa1QbWi+++KJmz54tSZo0aZJsNts1t3vllVfc\nMxkAAAAAeKlqQysyMtL6OCoqqkaGAQAAAIDaoNrQeuaZZ/TRRx+pX79+Gjt2bE3OBAAAAABe7bqX\nd09PT6+pOQAAAACg1rhuaDmdzpqaAwAAAABqjetedbCyslI7d+68bnDFxMQYHwoAAAAAvNl1Q6u8\nvFzTpk2rNrRsNhu/YwsAAAAA/sV1Q8vf35+QAgAAAIAf6LrnaAEAAAAAfjguhgEAAAAAhl03tD7/\n/POamgMAAAAAag0OHQQAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM\n0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAA\nADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgt\nAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAA\nwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIAAAAAwwgtAAAAADCM0AIA\nAAAAw34UodWzZ0/1799fAwcO1COPPCJJOnPmjFJTU5WQkKCnn35aZ8+etbbPyspSfHy8EhMTtW3b\nNmv5vn37lJycrISEBGVmZlrLy8vLNWHCBMXHx2vIkCE6duxYzT05AAAAAHXOjyK0bDab3n33XeXm\n5io7O1uStGjRIsXExGj9+vV64IEHlJWVJUk6ePCg8vPzlZeXp8WLFysjI0NOp1OSNHPmTGVmZmr9\n+vX65ptvtHXrVklSdna2goODtWHDBo0YMUKvvvqqZ54oAAAAgDrhRxFaTqdTlZWVVZZt3rxZKSkp\nkqSUlBRt2rRJkrRlyxYlJSXJ19dXkZGRioqKUmFhoYqLi1VWVqa2bdtKkgYOHGjd5/uPlZCQoB07\ndtTUUwMAAABQB/0oQstmsyk1NVWDBg3SihUrJEnffvutGjduLEkKCwtTSUmJJMnhcCg8PNy6r91u\nl8PhkMPhUNOmTa9aLkknT5601vn4+CgoKEinT5+ukecGAAAAoO7x9fQAkvT73/9eTZo0UUlJiVJT\nU3XHHXfIZrNV2eZfb9+MK4caAgAAAIA7/ChCq0mTJpKk0NBQ9e7dW4WFhWrUqJFOnTqlxo0bq7i4\nWKGhoZIu76k6fvy4dd8TJ07IbrdftdzhcMhut1uPf2W7iooKlZaWKiQk5N/OVVBQYPJpAgAAADXq\n8OHDssvf02N4pb1791a5IN8P5fHQOn/+vCorKxUQEKBz585p27ZtGjt2rHr27KlVq1Zp9OjRysnJ\nUa9evSRdvkJhWlqaRo4cKYfDoSNHjqht27ay2WwKDAxUYWGh2rRpo9zcXA0fPty6T05Ojtq1a6d1\n69apc+fOLs3WoUMHtz1vAAAAwN0CAwNVvLvI02N4pXvuuUctW7b8t9tVt3PG46F16tQpjR07Vjab\nTRUVFUpOTlbXrl11zz336Oc//7lWrlypiIgIzZ8/X5LUokULJSYmqm/fvvL19dWMGTOswwrT09M1\nZcoUXbhwQXFxcYqLi5MkDR48WJMmTVJ8fLxCQkI0d+5cjz1fAAAAALWfzckJS9dUUFDAHi0AAAB4\ntQMHDqj4rSJFh93h6VG8SlHxIYWlRru8R+ta3fCjuOogAAAAANQmhBYAAAAAGEZoAQAAAIBhhBYA\nAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBh\nhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAA\nAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZo\nAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAA\nGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYA\nAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBh\nhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAAAIBhhBYAAAAAGEZoAQAA\nAIBhvp4eAAAAALVPRUWFioqKPD2GV4qOjpaPj4+nx8BNIrQAAABgXFFRkf7w9heyh0V5ehSv4ig+\nrEdHSi1btvT0KLhJhBYAAADcwh4Wpchm0Z4eA/AIztECAAAAAMMILQAAAAAwjNACAAAAAMMILQAA\nAAAwjNACAAAAAMMILQAAAAAwjNACAAAAAMMILQAAAAAwjNACAAAAAMMILQAAAAAwjNACAAAAAMMI\nLQAAAAAwzNfTAwAAAJhUUVGhoqIiT4/htaKjo+Xj4+PpMQCvR2gBAIBapaioSKnvblBAkwhPj+J1\nyk4e1VvD49WyZUtPjwJ4PUILAADUOgFNIhTYLMrTYwCow+rUOVqffPKJ+vTpo4SEBC1atMjT4wAA\nAACopepMaFVWVmr27NlasmSJPvroI61du5bjtwEAAAC4RZ05dLCwsFBRUVGKiLh8vHbfvn21efNm\nRUdH3/BjcrLtjeNEWwAAANRmdSa0HA6HwsPDrdt2u11ffvnlTT1mUVGRPv/NbxXVKOxmx6tTDn9b\nLI37qbETbQneG0fwAgAAuEedCS3UXkVFRVqa8YjCQhp6ehSvUnz6n3pqRrbRK0sdOHDA2GPVJbwG\nnmf6Cmu8DjfG5OtQdvKosceqSy5/3e429niO4sPGHquuuPw1u9XoYx4p4d/DD3Wk5KjCdONHvkmS\nzel0Og3N86P2xRdf6De/+Y2WLFkiSdbFMEaPHn3N7QsKCmpsNgAAAADeq0OHDlctqzN7tNq0aaMj\nR47o6NGjCgsL09q1azV37txqt7/WFwsAAAAAXFFnQsvHx0cvvviiUlNT5XQ69cgjj9zUhTAAAAAA\noDp15tBBAAAAAKgpdeb3aAEAAABATSG0AAAAAMAwQgsAAAAADKszF8Oobe699159/vnnkqQ//elP\nevnll7V06VJlZ2dryZIl2rJli0JDQ6/atlWrVnrqqaf0X//1X5Kkt956S+fOndPYsWM980S83Btv\nvKG1a9fKx8dH9erVU69evVReXq7nn3/e2mb//v16/vnnlZeXp549e6pZs2Z67733rPUDBgxQZWWl\n1qxZ44mnUOu0bt1arVq10sWLF+Xr66sBAwZo5MiR+vOf/6zXXntNknT48GHZ7Xb5+/vrrrvu0i9+\n8QsPT137XHkdnE6nbDabkpKS9D//8z/6+9//rnPnzqmkpETNmzeXJM2YMUPt27f38MS105XX4dKl\nS7r99tvOoeh+AAAMjUlEQVT1y1/+UrfccouOHj2qpKQk3XnnndZrtGLFCvn68rbgZnz77beaM2eO\nCgsLFRQUJD8/P/30pz9VUFCQxowZo+bNm6uiokKNGzfWa6+9ptDQUOXk5GjKlClaunSpYmJiJEmb\nNm3S2LFj9etf/1rx8fEeflbe7/Tp0xo5cqRsNpuKi4tVr149NWrUSE6nU/v371fr1q2tfwcLFy5U\ns2bNPD1yrVXd+9fw8HAPT+YefEf1UjabTZK0Y8cOzZkzR0uWLFF4eLhsNptCQ0O1dOlSTZw4scq2\nklS/fn1t3LhRzzzzjEJCQjwye23xxRdf6E9/+pNyc3Pl6+ur06dP6+DBg5oyZUqV0Fq7dq2Sk5Ot\n22VlZXI4HLLb7SoqKqry+uDm+fv7KycnR5JUUlKiiRMnqrS0VOPGjVPXrl0lSU8++aQmT56sn/zk\nJ54ctVb7/uvwr3bv3q233npLb775Zg1PVfd8/3WYPHmyPvjgAz311FOSpNtuu63a1wg35mc/+5ke\nfvhhvf7665Kk48ePa8uWLQoKClLHjh2tv/Nz587V+++/b/0n51133aW8vDwrtNauXavWrVt75knU\nQiEhIcrNzZUkLViwQAEBAda/g/vuu49/BzWouvevtRWHDnopp9OpPXv2KD09XVlZWYqMjLTWPfzw\nw8rLy9N3331nbXuFj4+PHn30US1durTGZ65tiouLdeutt1r/AxwSEqKOHTsqKChIhYWF1nb5+fnq\n16+fdTsxMVFr166VdPmH6ffXwazQ0FDNmjWryh5E6fK/CS646l58fX982rdvryNHjnh6jFprx44d\n8vPz06OPPmotCw8P1xNPPFFlO6fTqbKyMgUFBVnLOnTooMLCQlVUVOjcuXM6fPiwWrVqVWOz12V8\nr6pZ1b1/LSkp0fjx4zV48GANHjxYn332mYcnNYPQ8lIXL17Uz372My1cuFC33357lXUBAQEaNGiQ\n3nnnnavuZ7PZ9MQTT2jNmjUqLS2toWlrp9jYWB0/flx9+vRRRkaGPv30U0lS3759rZD64osvFBIS\nYh0iZbPZFB8fr40bN0qS/vjHP6pHjx6eeQJ1RPPmzeV0OlVSUuLpUeqUCxcuKCUlRQMHDlRKSory\n8/M9PVKddOVNZEVFhbZv364WLVpY644cOaKUlBSlpKRo9uzZnhqx1jh48KDuvvvuatfv2bNHKSkp\n6tGjh3bs2KFBgwZZ62w2m7p06aKtW7dq8+bN6tWrV02MDFX9XjVu3DhPj1PrVff+NTMzUyNHjtSK\nFSv061//WtOnT/fckAZx6KCX8vX11b333qsVK1Zo2rRpV60fPny4Bg4cqNTU1KvWBQQEKCUlRcuW\nLVPDhg1rYtxa6ZZbblFOTo727NmjnTt3asKECUpLS1NSUpKGDh2qKVOmKC8v76o9ViEhIQoODlZe\nXp6io6N5DWoA/2NZ8xo2bMjhOD8CV95EnjhxQpGRkRo6dKi1jkMH3WvWrFkqKCiQn5+fXnjhhSqH\nDv72t7/VK6+8ooyMDEmyzmNctmyZSktLNXnyZA6trSF8r6pZ1b1/3bFjh77++mvr5/W5c+d0/vx5\n+fv7e2pUI9ij5aXq1aunX/3qV/ryyy+VlZV11frAwED169dPv/vd7655DtCTTz6p7OxsnT9/vibG\nrbVsNps6deqkcePG6cUXX9T69evVtGlTRUZGateuXdqwYYMSExOvut+VvWDfP3cL7vG3v/1NPj4+\n1sVhgLrkypvIjz/+WA0aNNDmzZs9PVKt1aJFC+3bt8+6nZ6errffflslJSVX/Rzu0aOHCgoKqixr\n06aNDhw4oNOnTysqKqpGZgZqWnXvX51Op/7whz8oNzdXubm5+vjjj70+siRCy2s5nU41aNBAWVlZ\n+uijj7Ry5cqrthk5cqQ++OADVVRUVLmfJAUHBysxMVHZ2dk1NnNtc+jQIR0+fNi6/dVXXykiIkKS\nlJSUpJdfflnNmzeX3W63trny9X/ooYc0atQoxcbG1uzQdcD3916VlJRo5syZGjZsmAcnqpvYi/jj\ncOV1aNCggaZNm6Z58+Z5eKLaKyYmRuXl5Vq+fLm17Pz589f8z86CggLrkPLvS0tL04QJE9w6J6ri\ne1XNqu79a2xsrJYtW2Ztt3//fk+NaBSHDnqpK9+4g4ODtXjxYg0bNuyq/7G/9dZb9dBDD1X5i/v9\nb/ipqal6//33uerdDTp37pxmz56t0tJS+fj4KCoqSrNmzZJ0eY9VZmam0tPTq9znytc6ICBAP/3p\nT2t85rqgvLxcKSkp1uXdBw4cqJEjR1bZhr/z7nfldbhyyeRu3bpVuRonasb3/663bt1aUVFRysvL\nU7t27Tw4Ve21cOFCzZkzR7/97W8VGhoqf39/paWlyel0qqCgQCkpKaqsrFRQUJBeeumlq+7frVs3\nD0xdt/HzoGZV9/51+vTpysjIUP/+/VVZWamOHTtq5syZnh3WAJuTlAcAAAAAozh0EAAAAAAMI7QA\nAAAAwDBCCwAAAAAMI7QAAAAAwDBCCwAAAAAMI7QAAAAAwDBCCwBQK0yZMkW/+tWv3PLYa9as0dNP\nP13t+t27d6t79+5u+dwAAO9EaAEAvM7w4cN1//336+LFizXy+ZKTk7VkyRLrdqtWrfS3v/2tyjb8\n4lMAwPcRWgAAr3L06FEVFhYqNDRUW7Zscfvnq6iouGoZUQUA+HcILQCAV8nNzVWXLl00cOBA5eTk\nVLvd4sWL1bVrV8XFxWnFihVV9kKVlpbqhRdeUExMjHr27Kk33njDul9OTo6GDh2ql19+WQ888IAW\nLFignJwcPf7445KkYcOGyel0qn///rrvvvuUn58vSXI6nVq6dKm6dOmibt26adWqVdZjTpkyRRkZ\nGRo1apTuvfdePfHEEyouLlZmZqY6deqkpKQk7d+/39p+0aJFiouL03333afExETt3LnT6NcQAOB+\nhBYAwKusXr1aSUlJ6tOnj7Zt26aSkpKrtvnkk0/0zjvv6J133tHGjRu1e/fuKnuhZs2apbKyMm3Z\nskXvvvuucnNztXLlSmt9YWGhbrvtNu3YsUP/+Z//Ken/92K99957kqQPP/xQn332mRITEyVJp06d\nUllZmbZu3aqXXnpJs2bN0tmzZ63HXLdunZ5//nnt2rVLvr6+GjJkiNq0aaPdu3crPj5ec+bMkSQd\nOnRI77//vlatWqXPPvtMS5YsUUREhOGvIgDA3QgtAIDX2LNnjxwOh3r27Knbb79dLVq00Jo1a67a\nbt26dRo0aJCio6PVoEEDjRs3Tk6nU5JUWVmpvLw8TZw4Uf7+/oqIiFBqaqpWr15t3d9ut+uJJ55Q\nvXr1VL9+fZdm8/Pz05gxY+Tj46Pu3bvrlltu0aFDh6z1Dz30kFq3bq369evroYcekr+/v/r37y+b\nzVZlj5aPj48uXryov/71r7p06ZKaNWum5s2b38yXDQDgAYQWAMBrrF69WrGxsQoICJAk9enTR7m5\nuVdtd/LkSTVt2tS6/f2P//GPf6iiokLNmjWzljVr1kwOh+Oa27sqJCRE9er9/4/Vhg0bqqyszLrd\nqFEj6+MGDRpUud2wYUOdO3dOknTbbbdp6tSp+s1vfqPY2FhNnDhRJ0+e/MHzAAA8y9fTAwAA4IoL\nFy4oPz9flZWV6tq1qySpvLxcZ8+erXJ+kySFhYXpxIkT1u3jx49bH996663y9fXV0aNHFR0dLUk6\nduyY7Ha7tY2nL3bRt29f9e3bV2VlZUpPT9frr7+uX/7ylx6dCQDww7BHCwDgFTZu3CgfHx/l5+dr\n9erVWr16tfLz89WxY8cqh/1JUmJiolatWqWioiKdP39eb7zxhhVP9erVU2JioubPn6+ysjIdPXpU\nb7/9tgYMGODyLI0bN77q8u4368qhjYcOHdLOnTtVXl4uPz8/NWjQoMqeMgCAd+A7NwDAK+Tm5mrQ\noEGy2+1q1KiR9efxxx/XmjVrqlyGPS4uTsOHD9eIESOUkJCg9u3bS5J1vtX06dPVsGFD9e7dW8OG\nDVP//v01aNAgl2cZN26cXnjhBd1///1at27dNbf5oXvFrmxfXl6u119/XTExMerWrZtKSkr0/PPP\n/6DHAgB4ns155b/QAACopYqKitS/f399+eWX7B0CANQIftoAAGqlTZs2qby8XGfOnNFrr72mnj17\nElkAgBrDTxwAQK20fPlydenSRfHx8fLz89OMGTM8PRIAoA7h0EEAAAAAMIw9WgAAAABgGKEFAAAA\nAIYRWgAAAABgGKEFAAAAAIYRWgAAAABgGKEFAAAAAIb9H0X/DweMzNm6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefb0cdd208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.barplot(x=\"Algorithms\", y=\"Time\", data=dat)\n",
    "plt.ylabel('Time (in Sec)', fontsize=12)\n",
    "plt.xlabel('Algorithms', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# THANK YOU\n",
    "\n",
    "### Any Questions, Querries, Suggestions, Feedbacks? "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
